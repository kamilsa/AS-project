{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.models.rnn import rnn, rnn_cell\n",
    "\n",
    "data = np.load('./kmeans0.npy')\n",
    "\n",
    "learning_rate = 0.001\n",
    "training_iters = 20000\n",
    "batch_size = 100\n",
    "display_step = 10\n",
    "\n",
    "# Network Parameters\n",
    "n_input = 10\n",
    "n_steps = 100 # timesteps\n",
    "n_hidden = 128 # hidden layer num of features\n",
    "n_out = 10 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepare_data(data, T):  # look back T steps max\n",
    "    data_num = data.shape[1]\n",
    "    data_size = data.shape[0]\n",
    "    \n",
    "    std = np.std(data, axis = 1)\n",
    "    mean = np.mean(data, axis = 1)\n",
    "    # first we need to normalize data (-1 to 1, demean and denormalization)\n",
    "    for i in range(data_num):\n",
    "        for j in range(data_size):\n",
    "            data[j,i] = (data[j,i]-mean[j])/std[j]\n",
    "    \n",
    "    data_num = data_num - T  # we need to start at X[T] to look back T steps \n",
    "    input_size = (T, data.shape[0])\n",
    "    output_size = data.shape[0]\n",
    "    all_input = np.zeros((T, data.shape[0], data_num))\n",
    "    all_output = np.zeros((output_size, data_num))\n",
    "    \n",
    "    for i in range(data_num):\n",
    "        all_output[:,i] = data[:,i+T]\n",
    "        for j in range(T):\n",
    "            all_input[j, :, i] = data[:, i+T-j-1]\n",
    "    \n",
    "    # five fold cross-validation\n",
    "    order = np.random.permutation(data_num)\n",
    "    training_num = int(data_num*4/5)\n",
    "    testing_num = data_num - training_num\n",
    "    training_order = order[0:training_num]\n",
    "    testing_order = order[training_num:data_num]\n",
    "    \n",
    "    training_input = all_input[:, :, training_order]\n",
    "    training_output = all_output[:, training_order]\n",
    "    \n",
    "    testing_input = all_input[:, :, testing_order]\n",
    "    testing_output = all_output[:, testing_order]\n",
    "    \n",
    "    return training_input.transpose((2,0,1)), training_output.transpose(), testing_input.transpose((2,0,1)), testing_output.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def RNN(_X, _istate, _weights, _biases):\n",
    "\n",
    "    # input shape: (batch_size, n_steps, n_input)\n",
    "    _X = tf.transpose(_X, [1, 0, 2])  # permute n_steps and batch_size\n",
    "    # Reshape to prepare input to hidden activation\n",
    "    _X = tf.reshape(_X, [-1, n_input]) # (n_steps*batch_size, n_input)\n",
    "    # Linear activation\n",
    "    _X = tf.matmul(_X, _weights['hidden']) + _biases['hidden']\n",
    "\n",
    "    # Define a basic RNN cell with tensorflow\n",
    "    basic_rnn_cell = rnn_cell.BasicRNNCell(n_hidden)\n",
    "    # Split data because rnn cell needs a list of inputs for the RNN inner loop\n",
    "    _X = tf.split(0, n_steps, _X) # n_steps * (batch_size, n_hidden)\n",
    "\n",
    "    # Get lstm cell output\n",
    "    outputs, states = rnn.rnn(basic_rnn_cell, _X, initial_state=_istate)\n",
    "\n",
    "    # Linear activation\n",
    "    # Get inner loop last output\n",
    "    return tf.matmul(outputs[-1], _weights['out']) + _biases['out']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# tf Graph input\n",
    "x = tf.placeholder(\"float\", [None, n_steps, n_input])\n",
    "# Tensorflow LSTM cell requires 2x n_hidden length (state & cell)\n",
    "istate = tf.placeholder(\"float\", [None, n_hidden])\n",
    "y = tf.placeholder(\"float\", [None, n_out])\n",
    "\n",
    "# Define weights\n",
    "weights = {\n",
    "    'hidden': tf.Variable(tf.random_normal([n_input, n_hidden])), # Hidden layer weights\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden, n_out]))\n",
    "}\n",
    "biases = {\n",
    "    'hidden': tf.Variable(tf.random_normal([n_hidden])),\n",
    "    'out': tf.Variable(tf.random_normal([n_out]))\n",
    "}\n",
    "\n",
    "pred = RNN(x, istate, weights, biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trX, trY, teX, teY = prepare_data(data, n_steps)\n",
    "# Define loss and optimizer\n",
    "cost = tf.reduce_sum(tf.pow(pred - y, 2))/(2 * trX.shape[0]) # Softmax loss\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost) # Adam Optimizer\n",
    "\n",
    "# Evaluate model\n",
    "correct_pred = tf.equal(tf.argmax(pred,1), tf.argmax(y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "# Initializing the variables\n",
    "init = tf.initialize_all_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0, Minibatch Loss= 5.287175\n",
      "Iter 1000, Minibatch Loss= 1.528048\n",
      "Iter 2000, Minibatch Loss= 0.697173\n",
      "Iter 3000, Minibatch Loss= 0.673743\n",
      "Iter 4000, Minibatch Loss= 0.418199\n",
      "Iter 5000, Minibatch Loss= 0.416554\n",
      "Iter 6000, Minibatch Loss= 0.372500\n",
      "Iter 7000, Minibatch Loss= 0.291872\n",
      "Iter 8000, Minibatch Loss= 0.258459\n",
      "Iter 9000, Minibatch Loss= 0.226515\n",
      "Iter 10000, Minibatch Loss= 0.247265\n",
      "Iter 11000, Minibatch Loss= 0.208210\n",
      "Iter 12000, Minibatch Loss= 0.225524\n",
      "Iter 13000, Minibatch Loss= 0.208063\n",
      "Iter 14000, Minibatch Loss= 0.162863\n",
      "Iter 15000, Minibatch Loss= 0.164219\n",
      "Iter 16000, Minibatch Loss= 0.181672\n",
      "Iter 17000, Minibatch Loss= 0.129802\n",
      "Iter 18000, Minibatch Loss= 0.144143\n",
      "Iter 19000, Minibatch Loss= 0.157080\n",
      "Optimization Finished!\n"
     ]
    }
   ],
   "source": [
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    step = 0\n",
    "    # Keep training until reach max iterations\n",
    "    while step * batch_size < training_iters:\n",
    "        start_ind = (step * batch_size)%trX.shape[0] \n",
    "        end_ind = (step+1)*batch_size%trX.shape[0]\n",
    "        if end_ind < start_ind:\n",
    "            batch_xs = np.concatenate((trX[start_ind:trX.shape[0],:,:], trX[0:end_ind,:,:]), axis=0)            \n",
    "            batch_ys = np.concatenate((trY[start_ind:trX.shape[0],:], trY[0:end_ind,:]), axis=0)\n",
    "        else:     \n",
    "            batch_xs = trX[start_ind:end_ind, :, :]\n",
    "            batch_ys = trY[start_ind:end_ind, :]\n",
    "        \n",
    "        sess.run(optimizer, feed_dict={x: batch_xs, y: batch_ys,\n",
    "                                       istate: np.zeros((batch_size, n_hidden))})\n",
    "        if step % display_step == 0:\n",
    "            # Calculate batch accuracy\n",
    "            acc = sess.run(accuracy, feed_dict={x: batch_xs, y: batch_ys, istate: np.zeros((batch_size, n_hidden))})\n",
    "            # Calculate batch loss\n",
    "            loss = sess.run(cost, feed_dict={x: batch_xs, y: batch_ys, istate: np.zeros((batch_size, n_hidden))})\n",
    "            print \"Iter \" + str(step*batch_size) + \", Minibatch Loss= \" + \"{:.6f}\".format(loss)\n",
    "        step += 1\n",
    "    print \"Optimization Finished!\"\n",
    "    # Calculate accuracy for 256 mnist test images\n",
    "    #test_len = 256\n",
    "    #test_data = teX\n",
    "    #test_label = mnist.test.labels[:test_len]\n",
    "    #print \"Testing Accuracy:\", sess.run(accuracy, feed_dict={x: test_data, y: test_label,\n",
    "    #                                                         istate: np.zeros((test_len, 2*n_hidden))})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:venv2]",
   "language": "python",
   "name": "conda-env-venv2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
