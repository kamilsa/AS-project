{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = np.load('./kmeans0.npy') # shape of temp is (10, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "T = 3 # look 3 steps forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def init_weights(shape):\n",
    "    return tf.Variable(tf.random_normal(shape, stddev=0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model(X, w_h, w_o):\n",
    "    h = tf.nn.sigmoid(tf.matmul(X, w_h))\n",
    "    return tf.matmul(h, w_o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def prepare_data(data, T):\n",
    "    # returning X[n-1...n-T] as input, X[n] as output\n",
    "    data_num = data.shape[1]\n",
    "    data_size = data.shape[0]\n",
    "    std = np.std(data, axis = 1)\n",
    "    mean = np.mean(data, axis = 1)\n",
    "    # first we need to normalize data (-1 to 1, demean and denormalization)\n",
    "    for i in range(data_num):\n",
    "        for j in range(data_size):\n",
    "            data[j,i] = (data[j,i]-mean[j])/std[j]\n",
    "    \n",
    "    data_num = data_num - T  # we need to start at X[T] to look back T steps \n",
    "    input_size = T*data.shape[0]\n",
    "    output_size = data.shape[0]\n",
    "    all_input = np.zeros((input_size, data_num))\n",
    "    all_output = np.zeros((output_size, data_num))\n",
    "    \n",
    "    for i in range(data_num):\n",
    "        all_output[:,i] = data[:,i+T]\n",
    "        for j in range(T):\n",
    "            all_input[j*data.shape[0] : (j+1)*data.shape[0], i] = data[:, i+T-j-1]\n",
    "    \n",
    "    # five fold cross-validation\n",
    "    order = np.random.permutation(data_num)\n",
    "    training_num = int(data_num*4/5)\n",
    "    testing_num = data_num - training_num\n",
    "    training_order = order[0:training_num]\n",
    "    testing_order = order[training_num:data_num]\n",
    "    \n",
    "    training_input = all_input[:, training_order]\n",
    "    training_output = all_output[:, training_order]\n",
    "    \n",
    "    testing_input = all_input[:, testing_order]\n",
    "    testing_output = all_output[:, testing_order]\n",
    "     \n",
    "    return training_input.transpose(), training_output.transpose(), testing_input.transpose(), testing_output.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trX, trY, teX, teY = prepare_data(data, T)\n",
    "\n",
    "X = tf.placeholder(\"float\", [None, trX.shape[1]])\n",
    "Y = tf.placeholder(\"float\", [None, trY.shape[1]])\n",
    "\n",
    "hidden_neuron_num = 100\n",
    "w_h = init_weights([trX.shape[1], hidden_neuron_num])  # 50 hidden neurons\n",
    "w_o = init_weights([hidden_neuron_num, trY.shape[1]])\n",
    "\n",
    "py_x = model(X, w_h, w_o)\n",
    "\n",
    "cost = tf.reduce_sum(tf.pow(Y-py_x, 2))/(2 * trX.shape[0])\n",
    "train_op = tf.train.GradientDescentOptimizer(0.05).minimize(cost)\n",
    "\n",
    "init = tf.initialize_all_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0001 cost= 5.054550648\n",
      "Epoch 0051 cost= 2.440073490\n",
      "Epoch 0101 cost= 2.062943459\n",
      "Epoch 0151 cost= 1.466448784\n",
      "Epoch 0201 cost= 1.192363381\n",
      "Epoch 0251 cost= 1.025780797\n",
      "Epoch 0301 cost= 0.885695517\n",
      "Epoch 0351 cost= 0.795196712\n",
      "Epoch 0401 cost= 0.743537784\n",
      "Epoch 0451 cost= 0.711046338\n",
      "Epoch 0501 cost= 0.684669375\n",
      "Epoch 0551 cost= 0.659503102\n",
      "Epoch 0601 cost= 0.634959519\n",
      "Epoch 0651 cost= 0.612139225\n",
      "Epoch 0701 cost= 0.592448771\n",
      "Epoch 0751 cost= 0.576682746\n",
      "Epoch 0801 cost= 0.564710081\n",
      "Epoch 0851 cost= 0.555762231\n",
      "Epoch 0901 cost= 0.548932195\n",
      "Epoch 0951 cost= 0.543476522\n",
      "Epoch 1001 cost= 0.538890004\n",
      "Epoch 1051 cost= 0.534860313\n",
      "Epoch 1101 cost= 0.531200767\n",
      "Epoch 1151 cost= 0.527795911\n",
      "Epoch 1201 cost= 0.524570525\n",
      "Epoch 1251 cost= 0.521476746\n",
      "Epoch 1301 cost= 0.518480361\n",
      "Epoch 1351 cost= 0.515555978\n",
      "Epoch 1401 cost= 0.512685359\n",
      "Epoch 1451 cost= 0.509857357\n",
      "Epoch 1501 cost= 0.507059753\n",
      "Epoch 1551 cost= 0.504287124\n",
      "Epoch 1601 cost= 0.501534402\n",
      "Epoch 1651 cost= 0.498799115\n",
      "Epoch 1701 cost= 0.496079266\n",
      "Epoch 1751 cost= 0.493374258\n",
      "Epoch 1801 cost= 0.490684420\n",
      "Epoch 1851 cost= 0.488013059\n",
      "Epoch 1901 cost= 0.485360205\n",
      "Epoch 1951 cost= 0.482729733\n",
      "Optimizer finished\n",
      "Training cost=  0.480179\n",
      "Testing...(L2 Loss Comparison)\n",
      "Testing cost= 0.517389\n",
      "Absolute L2 loss difference:  0.0372106\n"
     ]
    }
   ],
   "source": [
    "training_epochs = 2000\n",
    "display_step = 50\n",
    "batch_size = 128\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for epoch in range(training_epochs):\n",
    "        for i in range(int(trX.shape[0]/batch_size)):\n",
    "            start_ind = i*batch_size\n",
    "            end_ind = min((i+1)*batch_size, trX.shape[0])\n",
    "            sess.run(train_op, feed_dict={X: trX[start_ind:end_ind,:].reshape(batch_size,trX.shape[1]), Y:trY[start_ind:end_ind,:].reshape(batch_size, trY.shape[1])})\n",
    "           \n",
    "        if epoch % display_step == 0:\n",
    "            print \"Epoch\", '%04d' % (epoch+1), \"cost=\", \"{:.9f}\".format(sess.run(cost, feed_dict={X: trX, Y:trY}))\n",
    "        \n",
    "    print \"Optimizer finished\"\n",
    "    training_cost = sess.run(cost, feed_dict={X:trX, Y:trY})\n",
    "    print \"Training cost= \", training_cost\n",
    "    \n",
    "    \n",
    "    print \"Testing...(L2 Loss Comparison)\"\n",
    "    testing_cost = sess.run(tf.reduce_sum(tf.pow(Y-py_x, 2))/(2*teX.shape[0]),\n",
    "                            feed_dict={X: teX, Y: teY}) #same function as cost above\n",
    "    print \"Testing cost=\", testing_cost\n",
    "    print \"Absolute L2 loss difference: \", abs(training_cost - testing_cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:venv2]",
   "language": "python",
   "name": "conda-env-venv2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
